{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install dependencies\n",
        "!pip install elevenlabs pydub python-dotenv\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install openai\n",
        "!pip install -U openai-whisper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qeLWiBG9OVx",
        "outputId": "0b55fa94-c8d0-40e8-abea-3d024db0f73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting elevenlabs\n",
            "  Downloading elevenlabs-1.56.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (2.11.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (2.33.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (2.32.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (4.13.1)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (15.0.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->elevenlabs) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->elevenlabs) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->elevenlabs) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->elevenlabs) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->elevenlabs) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->elevenlabs) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->elevenlabs) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->elevenlabs) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->elevenlabs) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->elevenlabs) (1.3.1)\n",
            "Downloading elevenlabs-1.56.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pydub, python-dotenv, elevenlabs\n",
            "Successfully installed elevenlabs-1.56.0 pydub-0.25.1 python-dotenv-1.1.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=ad29189872d87b89f6cf0afddbecb8355fdbb987e4ed586587e736b2bab5c972\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting input audio into a text file##"
      ],
      "metadata": {
        "id": "gynuC1wHu5Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "\n",
        "WHISPER_MODEL_SIZE = \"base\"\n",
        "SUPPORTED_AUDIO_EXTENSIONS = ['.mp3', '.wav', '.m4a', '.ogg', '.flac']\n",
        "SUPPORTED_TEXT_EXTENSIONS = ['.txt', '.md'] # Add other text formats if needed\n",
        "\n",
        "\n",
        "import whisper\n",
        "model = whisper.load_model(WHISPER_MODEL_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    \"\"\"Transcribes an audio file using the loaded Whisper model.\"\"\"\n",
        "    print(f\"\\nAttempting to transcribe audio file: {file_path}\")\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        # Perform the transcription\n",
        "        result = model.transcribe(file_path, fp16=False) # fp16=False for wider CPU compatibility\n",
        "        transcript = result[\"text\"]\n",
        "        end_time = time.time()\n",
        "        print(f\"Transcription successful ({end_time - start_time:.2f} seconds).\")\n",
        "        return transcript.strip() # Remove leading/trailing whitespace\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Audio file not found at {file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    \"\"\"Reads content from a text file.\"\"\"\n",
        "    print(f\"\\nReading text file: {file_path}\")\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        print(\"Text file read successfully.\")\n",
        "        return content.strip() # Remove leading/trailing whitespace\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Text file not found at {file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading text file: {e}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_input(file_path):\n",
        "    \"\"\"\n",
        "    Determines input type (text or audio) and processes accordingly.\n",
        "    Returns the text content (either original or transcribed).\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: Input file not found at {file_path}\")\n",
        "        return None\n",
        "\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "    file_extension = file_extension.lower()\n",
        "\n",
        "    print(f\"\\nProcessing input file: {os.path.basename(file_path)}\")\n",
        "    print(f\"Detected extension: {file_extension}\")\n",
        "\n",
        "    if file_extension in SUPPORTED_TEXT_EXTENSIONS:\n",
        "        print(\"Input Type: Text\")\n",
        "        return read_text_file(file_path)\n",
        "    elif file_extension in SUPPORTED_AUDIO_EXTENSIONS:\n",
        "        print(\"Input Type: Audio\")\n",
        "        return transcribe_audio(file_path)\n",
        "    else:\n",
        "        print(f\"Error: Unsupported file type: {file_extension}\")\n",
        "        print(f\"Supported text types: {SUPPORTED_TEXT_EXTENSIONS}\")\n",
        "        print(f\"Supported audio types: {SUPPORTED_AUDIO_EXTENSIONS}\")\n",
        "        return None\n",
        "\n",
        "# --- Main Execution Logic ---\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) < 2:\n",
        "        print(\"\\nUsage: python preprocess_demo.py <path_to_input_file.txt_or_audio>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # input_file = sys.argv[1]\n",
        "    input_file=\"/content/sample_audio.mp3\"\n",
        "\n",
        "    processed_text = preprocess_input(input_file)\n",
        "\n",
        "    if processed_text is not None:\n",
        "        print(\"\\n✅ Pre-processing Complete.\")\n",
        "        print(\"\\n--- Output Text for Next Stage (Script Parsing) ---\")\n",
        "        print(processed_text)\n",
        "        print(\"----------------------------------------------------\")\n",
        "\n",
        "        # Optional: Save the output to a file\n",
        "        # output_filename = os.path.splitext(os.path.basename(input_file))[0] + \"_processed.txt\"\n",
        "        with open(\"transcribed_script.txt\", \"w\", encoding='utf-8') as outfile:\n",
        "            outfile.write(processed_text)\n",
        "        # print(f\"\\nOutput also saved to: {output_filename}\")\n",
        "    else:\n",
        "        print(\"\\n Pre-processing failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37dmVq92S_O5",
        "outputId": "8e1802e0-137b-4d11-f23f-34970a0ac8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 77.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing input file: sample_audio.mp3\n",
            "Detected extension: .mp3\n",
            "Input Type: Audio\n",
            "\n",
            "Attempting to transcribe audio file: /content/sample_audio.mp3\n",
            "Transcription successful (34.31 seconds).\n",
            "\n",
            "✅ Pre-processing Complete.\n",
            "\n",
            "--- Output Text for Next Stage (Script Parsing) ---\n",
            "SFX, gender-arrain, narrated, the schedule said that the last bus came at 210, now it was 213, and the bench was in empty anymore. SFX, clock chimes twice, narrated, he hadn't seen anyone arrive, just a man in a grey coat sitting on the far end of the bench, not moving, not blinking. SFX, rain gets heavier, narrated, the man checked the road, still no headlights, and no bus, but the other guy, he stood up like he'd heard it coming. SFX, bus, slows down and breaks, narrated, he stepped into the street, and vanished. SFX, sees transverses.\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting input text into script with dialogues and SFX##"
      ],
      "metadata": {
        "id": "ZcQf69jSumy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "# --- Configuration ---\n",
        "client = OpenAI(api_key=userdata.get('gpt-api-key'))\n",
        "MODEL_TO_USE = \"gpt-4-turbo\"\n",
        "\n",
        "def load_text_from_file(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_parsing_prompt(script_text):\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "You are a professional script formatter and dialogue editor.\n",
        "\n",
        "Your task is to convert the raw story text below into a properly formatted screenplay-style block using generic character names like CHARACTER1, CHARACTER2, etc., and preserving narration and sound effects inline.\n",
        "\n",
        "Please follow this **exact format**:\n",
        "\n",
        "SCRIPT = \\\"\\\"\\\"\n",
        "NARRATOR: This is a narration line.\n",
        "CHARACTER1: Their first line of dialogue.\n",
        "[SFX: Description of sound]\n",
        "CHARACTER2: Their reply.\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Formatting rules:\n",
        "- Use **NARRATOR** for all third-person descriptions or scene-setting lines.\n",
        "- For dialogue, assign character lines sequentially using **CHARACTER1**, **CHARACTER2**, etc., in the order they appear.\n",
        "- Maintain consistency (i.e., if the same person speaks again, use the same character number).\n",
        "- **Sound effects must remain inline** and be formatted like: [SFX: Description of sound]\n",
        "- Do NOT move sound effects to the top or bottom — they must appear exactly where they happen in the story.\n",
        "- Do NOT skip any dialogue, narration, or SFX — include every sentence.\n",
        "- Do NOT output any JSON, markdown, or explanations — only output the SCRIPT block.\n",
        "\n",
        "Script to convert:\n",
        "--- START SCRIPT ---\n",
        "{script_text}\n",
        "--- END SCRIPT ---\n",
        "\n",
        "Now format the above into the SCRIPT = \\\\\\\"\\\"\\\" ... \\\\\\\"\\\"\\\" block below:\n",
        "\"\"\"\n",
        "\n",
        "  return prompt.strip()\n",
        "\n",
        "def parse_script_with_llm(script_text):\n",
        "    if not script_text:\n",
        "        return None\n",
        "\n",
        "    prompt = create_parsing_prompt(script_text)\n",
        "    print(\"\\n--- Sending Prompt to LLM ---\\n...\")\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_TO_USE,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        response_content = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Remove formatting if it's wrapped in markdown code block\n",
        "        if response_content.startswith(\"```\"):\n",
        "            response_content = \"\\n\".join(response_content.split(\"\\n\")[1:-1]).strip()\n",
        "\n",
        "        print(\"\\n✅ Script Parsing Complete.\")\n",
        "        print(\"\\n--- Structured Script Output ---\")\n",
        "        print(response_content)\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "        return response_content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during LLM API call or processing: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Main Execution Logic ---\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) < 2:\n",
        "        print(\"\\nUsage: python parse_script_demo.py <path_to_processed_script.txt>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # input_script_file = sys.argv[1]\n",
        "    # For testing you might hardcode:\n",
        "    input_script_file = \"/content/sample_script.txt\"\n",
        "\n",
        "    raw_script = load_text_from_file(input_script_file)\n",
        "\n",
        "    if raw_script:\n",
        "        structured_output = parse_script_with_llm(raw_script)\n",
        "\n",
        "        # Optionally save to a .txt file\n",
        "        if structured_output:\n",
        "            output_filename = os.path.splitext(os.path.basename(input_script_file))[0] + \"_formatted_script.txt\"\n",
        "            with open(output_filename, \"w\", encoding='utf-8') as outfile:\n",
        "                outfile.write(structured_output)\n",
        "            print(f\"\\nOutput also saved to: {output_filename}\")\n",
        "        else:\n",
        "            print(\"\\n Script Parsing failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4uSOEw1VHQN",
        "outputId": "cdd212f7-4be9-46cf-95c2-8f3ed5cb950f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sending Prompt to LLM ---\n",
            "...\n",
            "\n",
            "✅ Script Parsing Complete.\n",
            "\n",
            "--- Structured Script Output ---\n",
            "SCRIPT = \"\"\" \n",
            "NARRATOR: The diner sat on the edge of nowhere. One flickering neon sign. Two customers. And one waitress who hadn’t spoken in ten minutes.\n",
            "[SFX: Neon light buzzing, occasional car passing in the distance, faint hum of a refrigerator.]\n",
            "[SFX: Distant thunder. Wind rustles through a cracked window. Door creaks open. Bell jingles faintly.]\n",
            "CHARACTER1: Evening. You still serving?\n",
            "CHARACTER2: Coffee’s fresh. Sit anywhere.\n",
            "[SFX: Chair scraping across the floor. A coffee pot clinks against a mug.]\n",
            "NARRATOR: Jack had driven 300 miles without stopping. Something about this place told him he should’ve kept going.\n",
            "[SFX: Coffee pouring. Wind slams against the window suddenly.]\n",
            "CHARACTER2: Storm's coming. They always stop here when it rains.\n",
            "CHARACTER1: They?\n",
            "[SFX: Buzzing intensifies for a moment, then dies down. Clock ticks]\n",
            "NARRATOR: She didn’t answer. Just stared at the door. Waiting.\n",
            "[SFX: Tires screech faintly in the distance. Then silence.]\n",
            "CHARACTER1: What kind of storm?\n",
            "CHARACTER2: The kind that doesn’t show up on maps.\n",
            "[SFX: Bell above the door jingles—without the door opening.]\n",
            "NARRATOR: Jack turned, but no one was there. Just his reflection in the glass— and something behind it.\n",
            "[SFX: Sudden electric pop. Lights flicker.]\n",
            "CHARACTER2: You should’ve kept driving.\n",
            "[SFX: Wind howls. The bell jingles again—louder. Lights go out completely.]\n",
            "NARRATOR: The storm had arrived.\n",
            "[SFX: Silence. Then slow footsteps, not Jack’s, approaching across the tile floor.]\n",
            "\"\"\"\n",
            "-----------------------------\n",
            "\n",
            "Output also saved to: sample_script_formatted_script.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import uuid\n",
        "from dotenv import load_dotenv\n",
        "from elevenlabs.client import ElevenLabs\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import userdata\n",
        "# Load .env vars\n",
        "load_dotenv()\n",
        "\n",
        "# Set up ElevenLabs client (new style)\n",
        "client = ElevenLabs(\n",
        "    api_key=userdata.get('eleven-labs-key'),\n",
        "                    )\n",
        "\n",
        "# Voice map (update voice IDs as per your ElevenLabs voices)\n",
        "VOICE_MAP = {\n",
        "    \"NARRATOR\": \"pNInz6obpgDQGcFmaJgB\", # Narrator\n",
        "    \"CHARACTER1\": \"JBFqnCBsd6RMkjVDRZzb\",  # Voice 1\n",
        "    \"CHARACTER2\": \"EXAVITQu4vr4xnSDxMaL\",  # Voice 2\n",
        "    \"CHARACTER3\": \"MF3mGyEYCl7XYWbV9V6O\",  # Voice 3\n",
        "    \"CHARACTER4\": \"ErXwobaYiN019PkySvjV\",  # Voice 4\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def extract_script_string(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Find the content between triple quotes\n",
        "    if '\"\"\"' in content:\n",
        "        parts = content.split('\"\"\"')\n",
        "        if len(parts) >= 3:\n",
        "            return f'\"\"\"{parts[1]}\"\"\"'\n",
        "        else:\n",
        "            raise ValueError(\"Triple quotes not properly found in the file.\")\n",
        "    else:\n",
        "        raise ValueError(\"No triple-quoted string found in the file.\")\n",
        "\n",
        "# Usage\n",
        "SCRIPT = extract_script_string(\"/content/sample_script_formatted_script.txt\")\n",
        "\n",
        "\n",
        "# Voice generation: handle generator output\n",
        "def generate_voice_audio(text, voice_id):\n",
        "    audio_gen = client.text_to_speech.convert(\n",
        "        text=text,\n",
        "        voice_id=voice_id,\n",
        "        model_id=\"eleven_multilingual_v2\",\n",
        "        output_format=\"mp3_44100_128\",\n",
        "    )\n",
        "    filename = f\"/content/voice_{uuid.uuid4()}.mp3\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        for chunk in audio_gen:\n",
        "            f.write(chunk)\n",
        "    return filename\n",
        "\n",
        "# SFX generation: handle generator output\n",
        "def generate_sfx(prompt):\n",
        "    sfx_gen = client.text_to_sound_effects.convert(text=prompt)\n",
        "    filename = f\"/content/sfx_{uuid.uuid4()}.mp3\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        for chunk in sfx_gen:\n",
        "            f.write(chunk)\n",
        "    return filename\n",
        "\n",
        "\n",
        "# Parse script and generate audio segments\n",
        "def parse_script(script):\n",
        "    lines = script.strip().splitlines()\n",
        "    audio_segments = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "\n",
        "        # Sound Effect\n",
        "        if re.match(r'\\[SFX: .*?\\]', line):\n",
        "            sfx_prompt = re.search(r'\\[SFX:\\s*(.*?)\\]', line).group(1)\n",
        "            sfx_file = generate_sfx(sfx_prompt)\n",
        "            seg = AudioSegment.from_file(sfx_file)\n",
        "            audio_segments.append(seg)\n",
        "\n",
        "        # Dialogue\n",
        "        elif \":\" in line:\n",
        "            speaker, text = line.split(\":\", 1)\n",
        "            speaker = speaker.strip()\n",
        "            voice_id = VOICE_MAP.get(speaker)\n",
        "            if voice_id:\n",
        "                voice_file = generate_voice_audio(text.strip(), voice_id)\n",
        "                seg = AudioSegment.from_file(voice_file)\n",
        "                audio_segments.append(seg)\n",
        "\n",
        "    return audio_segments\n",
        "\n",
        "# Merge all audio clips into one podcast file\n",
        "def combine_segments(segments, output_file=\"/content/final_podcast.mp3\"):\n",
        "    final = AudioSegment.silent(duration=500)\n",
        "    for seg in segments:\n",
        "        final += seg + AudioSegment.silent(duration=400)\n",
        "    final.export(output_file, format=\"mp3\")\n",
        "    return output_file\n",
        "\n",
        "# Run full pipeline\n",
        "segments = parse_script(SCRIPT)\n",
        "final_path = combine_segments(segments)\n",
        "\n",
        "# Playback in Colab\n",
        "display(Audio(filename=final_path))\n",
        "print(f\"Final podcast saved at: {final_path}\")\n"
      ],
      "metadata": {
        "id": "gTRFCyus_Mzf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "785842cd-1836-4731-9856-76d5c598b7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ApiError",
          "evalue": "status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 19 credits remaining, while 38 credits are required for this request.'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8e170035c5b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# 🚀 Run full pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCRIPT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0mfinal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8e170035c5b1>\u001b[0m in \u001b[0;36mparse_script\u001b[0;34m(script)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mvoice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOICE_MAP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvoice_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mvoice_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_voice_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoice_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0maudio_segments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8e170035c5b1>\u001b[0m in \u001b[0;36mgenerate_voice_audio\u001b[0;34m(text, voice_id)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/content/voice_{uuid.uuid4()}.mp3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maudio_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/elevenlabs/text_to_speech/client.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, language_code, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, use_pvc_as_ivc, apply_text_normalization, apply_language_text_normalization, request_options)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mApiError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_response_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     def convert_with_timestamps(\n",
            "\u001b[0;31mApiError\u001b[0m: status_code: 401, body: {'detail': {'status': 'quota_exceeded', 'message': 'This request exceeds your quota of 10000. You have 19 credits remaining, while 38 credits are required for this request.'}}"
          ]
        }
      ]
    }
  ]
}